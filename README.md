# Nvidia Jetson OpenClaw

This repository contains notes and scripts for setting up OpenClaw on a Nvidia Jetson Orin Nano Super Developer Kit. These are growing notes as I continue to experiment.

Goal: Turn my Nvidia Jetson Orin Nano Super Developer Kit into 24/7 AI assistant that can help me with coding, research, and other tasks.

## Tested Device

- Nvidia Jetson Orin Nano Super Developer Kit

![Image](https://github.com/user-attachments/assets/2c9e2a44-a2f3-4d04-994d-efbac5ea7fb5)

## Tested AI Backends

- Google Antigravity Models
- Gemini CLI via Vertex AI
- Claude Models via Azure Foundry
- Claude Code via Azure Foundry Claude models
- OpenAI Models via Azure Foundry
- OpenAI Codex via Azure Foundry OpenAI models
- OpenAI API models

## OpenClaw Setup

1. [Google AI Plan and API Setup](google_ai_plan.md)
2. [Azure Deployment](azure_deployment.md)
3. [Install Jetson Linux](jetson_linux.md)
4. [Connect the kit via SSH](ssh_connection.md)
5. [Set up File Sharing](file_sharing.md)
6. [Install basic tools](basic_tools.md)
7. [Install OpenClaw](openclaw.md)
8. [Install coding agents](coding_agents.md)
9. [Set up Telegram bot & groups](telegram.md)
10. [Configure shell environment](.bashrc)

## Optional Setup

* [Change Power Mode](change_power_mode.md)
* [Memory Optimization](memory_optimization.md)
* [Gog CLI](gog_cli.md)

## Custom MCP Server

[BibleMate AI MCP](biblemate_ai.md)